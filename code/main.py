import sys
import os
import subprocess
import atexit
import json

# PyQt5ë¥¼ ë¨¼ì € ì„í¬íŠ¸í•˜ê³  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
import PyQt5
if hasattr(PyQt5, 'QtCore'):
    pyqt_plugins_path = os.path.join(os.path.dirname(PyQt5.__file__), "Qt5", "plugins")
    os.environ["QT_QPA_PLATFORM_PLUGIN_PATH"] = pyqt_plugins_path

from PyQt5.QtWidgets import QApplication
from PyQt5.QtGui import QGuiApplication, QKeyEvent, QImage
from PyQt5.QtQml import QQmlApplicationEngine
from PyQt5.QtCore import QUrl, QObject, pyqtSignal, pyqtSlot, QVariant, Qt, QMetaObject, QEvent, QThread, QGenericArgument, Q_ARG

# ê²Œì„ ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
import torch
from ultralytics import YOLO
from argparse import Namespace

# --- ì¶”ê°€ ì„í¬íŠ¸ ---
from avatar_qt import MannequinRenderer
import cv2
import numpy as np

import platform
import serial
# -----------------

# merge_test í´ë”ë¥¼ ëª¨ë“ˆ ê²€ìƒ‰ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.abspath('merge_test'))
sys.path.insert(0, os.path.abspath('merge_test/tools'))
from pages.Single_Player_app import SinglePlayerApp
from pages.Multi_Player_app import MultiPlayerApp
from video_to_json import create_json_from_video

def delete_output_files():
    """ì¶œë ¥ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜"""
    print("Deleting output files...")
    files_to_delete = [
        "resource/output.mp4",
        "resource/output_character.mp4",
        "resource/output.json",
        "resource/output_with_audio.mp4",
        "resource/output_character_with_audio.mp4"
    ]
    for f in files_to_delete:
        if os.path.exists(f):
            try:
                os.remove(f)
                print(f"Deleted {f}")
            except OSError as e:
                print(f"Error deleting file {f}: {e}")
        else:
            print(f"File not found, skipping: {f}")

# âŒ¨ï¸ ì „ì—­ í‚¤ ì´ë²¤íŠ¸ í•„í„°: 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì•± ì¢…ë£Œ
class AppEventFilter(QObject):
    def __init__(self, control_bridge, parent=None):
        super().__init__(parent)
        self.control_bridge = control_bridge

    def eventFilter(self, obj, event):
        if event.type() == QEvent.KeyPress and event.key() == Qt.Key_Q:
            if self.control_bridge.game_window and self.control_bridge.game_window.isVisible():
                print("'q' key pressed. Closing game window.")
                self.control_bridge.game_window.close()
                return True
            else:
                print("'q' key pressed. Terminating application.")
                QGuiApplication.instance().quit()
                return True
        return super().eventFilter(obj, event)

# ğŸ”” ì‹œê·¸ë„ ë¸Œë¦¬ì§€: QMLì—ì„œ Pythonìœ¼ë¡œ ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ê³ , ë‹¤ì‹œ ë‹¤ë¥¸ QMLë¡œ ëª…ë ¹ì„ ë³´ëƒ…ë‹ˆë‹¤.
class SignalBridge(QObject):
    videoSelected = pyqtSignal(str)

    def __init__(self, main_view_window, parent=None):
        super().__init__(parent)
        self.main_view_window = main_view_window
        self.videoSelected.connect(self.onVideoSelected)

    @pyqtSlot(str)
    def onVideoSelected(self, videoPath):
        print(f"ğŸ¬ ì‹œê·¸ë„ ìˆ˜ì‹  â†’ ì˜ìƒ ë³€ê²½: {videoPath}")
        self.main_view_window.playVideo(videoPath)


# --- ì•„ë°”íƒ€ ë³€í™˜ ì‘ì—…ì ---
class ConversionWorker(QObject):
    finished = pyqtSignal()
    totalProgress = pyqtSignal(int) # ì „ì²´ ì§„í–‰ë¥  (0-100)
    log = pyqtSignal(str)

    def __init__(self, avatar_name, model, device, use_half, reference_video_path, parent=None):
        super().__init__(parent)
        self.renderer = None
        self.avatar_name = avatar_name
        self.model = model
        self.device = device
        self.use_half = use_half
        self.reference_video_path = reference_video_path

    @pyqtSlot()
    def run(self):
        """Long-running task for avatar conversion."""
        try:
            # Stage 1: Video to JSON
            self.totalProgress.emit(0)
            video_in = "resource/output.mp4"
            json_out = "resource/output.json"
            self.log.emit(f"Starting video to JSON conversion for {video_in}")
            create_json_from_video(
                video_path=video_in,
                model_path='merge_test/yolov8l-pose.pt', # Using the same model as main app
                output_json=json_out,
                imgsz=640,
                device=self.device,
                use_half=self.use_half,
                step=1 # Process every 3rd frame to match renderer stride
            )
            self.log.emit(f"Successfully created {json_out}.")
            self.totalProgress.emit(10)

            # Stage 2: Render frames (10% -> 60%)
            self.log.emit("Loading assets and rendering frames...")
            assets_dir = self.avatar_name
            self.renderer = MannequinRenderer(
                json_path=json_out,
                assets_dir=assets_dir,
                stride=1 # JSON already has a stride, so renderer uses 1
            )
            self.renderer.log.connect(self.log.emit)
            self.renderer.error.connect(self.log.emit)
            self.renderer.progress.connect(self.onRenderProgress)
            self.renderer.playReady.connect(self.write_video)
            
            self.renderer.run()

        except Exception as e:
            self.log.emit(f"Error during conversion: {e}")
        finally:
            self.finished.emit()

    @pyqtSlot(int)
    def onRenderProgress(self, value):
        # ë Œë”ë§ ì§„í–‰ë¥ (0-100)ì„ ì „ì²´ ì§„í–‰ë¥ ì˜ 10-60% ë²”ìœ„ë¡œ ë§¤í•‘
        total_progress = 10 + int(value * 0.5)
        self.totalProgress.emit(total_progress)

    def write_video(self, qframes, fps):
        # Stage 2 is done, we are at 60%.
        self.totalProgress.emit(60)
        if not qframes:
            self.log.emit("No frames to write.")
            return

        video_out = "resource/output_character.mp4"
        
        try:
            first_frame = qframes[0]
            height, width = first_frame.height(), first_frame.width()

            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            writer = cv2.VideoWriter(video_out, fourcc, fps, (width, height))

            self.log.emit(f"Writing video to {video_out}...")
            total_frames = len(qframes)
            for i, qframe in enumerate(qframes):
                img = qframe.convertToFormat(QImage.Format.Format_RGB888)
                ptr = img.constBits()
                ptr.setsize(img.sizeInBytes())
                arr = np.array(ptr).reshape(height, width, 3)  # RGB
                bgr_frame = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)
                writer.write(bgr_frame)
                
                # Stage 3: Writing video (60% -> 90% of total progress)
                video_progress = int((i + 1) * 100 / total_frames)
                total_progress = 60 + int(video_progress * 0.3)
                self.totalProgress.emit(total_progress)

            writer.release()
            self.log.emit("Finished writing video.")

            # Stage 4: Merge audio (90% -> 100%)
            self.log.emit("Merging audio to final video...")
            self._merge_audio_to_final_video()
            self.totalProgress.emit(100)

        except Exception as e:
            self.log.emit(f"Error writing video or merging audio: {e}")

    def _merge_audio_to_final_video(self):
        self.log.emit(f"Starting final audio merge...")
        character_video = "resource/output_character.mp4"
        output_video_with_audio = "resource/output_character_with_audio.mp4"

        if not self.reference_video_path:
            self.log.emit("No reference video path provided for audio merge, skipping.")
            # Copy silent video to the final name so playback doesn't fail
            import shutil
            shutil.copy(character_video, output_video_with_audio)
            return

        command = [
            'ffmpeg',
            '-y',  # Overwrite output file
            '-i', character_video,
            '-i', self.reference_video_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-map', '0:v:0',
            '-map', '1:a:0',
            '-shortest',
            output_video_with_audio
        ]

        try:
            result = subprocess.run(command, check=True, capture_output=True, text=True)
            self.log.emit(f"Successfully merged audio to {output_video_with_audio}")
        except subprocess.CalledProcessError as e:
            self.log.emit(f"FFmpeg error during final merge: {e.stderr}")
        except FileNotFoundError:
            self.log.emit("'ffmpeg' not found. Cannot merge audio.")


# ğŸ® ì»¨íŠ¸ë¡¤ ë¸Œë¦¬ì§€: ë²„íŠ¼ í´ë¦­ ì‹œ í™”ë©´ ì „í™˜ ì‹ í˜¸ë¥¼ ë³´ëƒ…ë‹ˆë‹¤.
class ControlBridge(QObject):
    showVideoSelect = pyqtSignal()
    gameStarted = pyqtSignal()
    showPostGameMenu = pyqtSignal(str)
    showRank = pyqtSignal(int)
    showMultiplayerResult = pyqtSignal(str)
    showMainMenu = pyqtSignal()
    showAvatarScreen = pyqtSignal()
    showCredits = pyqtSignal()
    conversionStarted = pyqtSignal()
    conversionFinishedForControl = pyqtSignal()
    avatarNext = pyqtSignal()
    avatarPrevious = pyqtSignal()

    def __init__(self, screens, signalBridge, model_data, view_window, parent=None):
        super().__init__(parent)
        self.screens = screens
        self.signalBridge = signalBridge
        self.model = model_data['model']
        self.device = model_data['device']
        self.use_half = model_data['use_half']
        self.view_window = view_window
        self.game_window = None
        self.last_video_path = None
        self.conversion_thread = None
        self.conversion_worker = None
        self.current_avatar_index = 0
        self.is_multi_player = False
        
        # OSë³„ í¬íŠ¸ ì„ íƒ
        if platform.system() == "Windows":
            port = "COM7"
        elif platform.system() == "Linux":
            port = "/dev/ttyACM0"
        else:
            raise Exception("ì§€ì›í•˜ì§€ ì•ŠëŠ” OS")
        
        self.ser = serial.Serial(port=port, baudrate=115200, timeout=1)

    @pyqtSlot(int)
    def onAvatarIndexChanged(self, index):
        print(f"Avatar index changed to: {index}")
        self.current_avatar_index = index

    @pyqtSlot(int)
    def choose(self, index):
        avatar_map = {0: "naruto_parts", 1: "dady_parts", 2: "ren_parts", 3: "rumi_parts"}
        avatar_name = avatar_map.get(index, "dady_parts") # Default to dady_parts if index is wrong
        self.startAvatarConversionWithName(avatar_name)

    @pyqtSlot(str)
    def selectVideo(self, videoPath):
        print(f"ğŸ¬ QMLì—ì„œ ì˜ìƒ ì„ íƒ: {videoPath}")
        self.signalBridge.videoSelected.emit(videoPath)

    @pyqtSlot()
    def openVideoSelectWindow(self):
        print("ğŸ¬ ë²„íŠ¼ í´ë¦­ë¨: Video Select í™”ë©´ìœ¼ë¡œ ì „í™˜ ì‹ í˜¸ ì „ì†¡ (1ì¸ ëª¨ë“œ)")
        self.is_multi_player = False
        self.showVideoSelect.emit()

    @pyqtSlot()
    def openVideoSelectWindowForMultiplayer(self):
        print("ğŸ¬ ë²„íŠ¼ í´ë¦­ë¨: Video Select í™”ë©´ìœ¼ë¡œ ì „í™˜ ì‹ í˜¸ ì „ì†¡ (2ì¸ ëª¨ë“œ)")
        self.is_multi_player = True
        self.showVideoSelect.emit()
        
    @pyqtSlot()
    def avatarButtonClicked(self):
        print("ğŸ¬ ì•„ë°”íƒ€ ë²„íŠ¼ í´ë¦­ë¨: ì•„ë°”íƒ€ í™”ë©´ìœ¼ë¡œ ì „í™˜ ì‹ í˜¸ ì „ì†¡")
        self.showAvatarScreen.emit()

    @pyqtSlot()
    def onShowCredits(self):
        print("ğŸ¬ í¬ë ˆë”§ ë²„íŠ¼ í´ë¦­ë¨: í¬ë ˆë”§ ì‹ í˜¸ ì „ì†¡")
        self.showCredits.emit()
        
    @pyqtSlot(str)
    def startAvatarConversionWithName(self, avatar_name):
        print(f"ğŸ”„ ì•„ë°”íƒ€ ë³€í™˜ ì‹œì‘ ì‹ í˜¸ ìˆ˜ì‹ : {avatar_name}")
        if self.conversion_thread and self.conversion_thread.isRunning():
            print("â— Conversion is already in progress.")
            return

        # ì»¨íŠ¸ë¡¤ UIë¥¼ "ë³€í™˜ ì¤‘" ìƒíƒœë¡œ ë³€ê²½
        self.conversionStarted.emit()
        # ë©”ì¸ ë·°ë¥¼ ë¡œë”© í™”ë©´ìœ¼ë¡œ ë³€ê²½
        QMetaObject.invokeMethod(self.view_window, "showAvatarLoading", Qt.QueuedConnection)

        self.conversion_thread = QThread()
        self.conversion_worker = ConversionWorker(
            avatar_name, self.model, self.device, self.use_half, self.last_video_path
        )
        self.conversion_worker.moveToThread(self.conversion_thread)

        self.conversion_thread.started.connect(self.conversion_worker.run)
        self.conversion_worker.finished.connect(self.conversion_thread.quit)
        self.conversion_worker.finished.connect(self.conversion_worker.deleteLater)
        self.conversion_worker.finished.connect(self.conversion_thread.deleteLater)
        self.conversion_thread.finished.connect(self.onConversionThreadFinished)
        
        self.conversion_worker.totalProgress.connect(self.updateConversionProgress)
        self.conversion_worker.finished.connect(self.onConversionFinished)
        self.conversion_worker.log.connect(lambda msg: print(f"[CONVERSION]: {msg}"))

        self.conversion_thread.start()

    @pyqtSlot()
    def startAvatarConversion(self):
        print(f"startAvatarConversion called from AvatarControl with index {self.current_avatar_index}")
        self.choose(self.current_avatar_index)

    def onConversionThreadFinished(self):
        print("Conversion thread finished, setting to None.")
        self.conversion_thread = None

    @pyqtSlot(int)
    def updateConversionProgress(self, value):
        loader = self.view_window.findChild(QObject, "avatarLoader")
        if loader and loader.item():
            loader.item().setProperty("conversionProgress", value / 100.0)

    def onConversionFinished(self):
        print("âœ… Avatar conversion finished!")
        # ì»¨íŠ¸ë¡¤ UIë¥¼ "ë³€í™˜ ì™„ë£Œ" ìƒíƒœë¡œ ë³€ê²½
        self.conversionFinishedForControl.emit()

    @pyqtSlot()
    def playConvertedVideo(self):
        print("ğŸ¬ ë³€í™˜ëœ ë¹„ë””ì˜¤ ì¬ìƒ ìš”ì²­")
        video_path = "resource/output_character_with_audio.mp4"
        if os.path.exists(video_path) and os.path.getsize(video_path) > 0:
            QMetaObject.invokeMethod(self.view_window, "playConvertedVideoInMain", Qt.QueuedConnection, Q_ARG(QVariant, video_path))
        else:
            print(f"â— Error: Converted video file not found or is empty at {video_path}")
            self.goToMainMenu()

    @pyqtSlot()
    def onAvatarNext(self):
        self.avatarNext.emit()

    @pyqtSlot()
    def onAvatarPrevious(self):
        self.avatarPrevious.emit()

    @pyqtSlot()
    def goToMainMenu(self):
        print("ğŸ¬ ë©”ì¸ ë©”ë‰´ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.")
        delete_output_files()
        QMetaObject.invokeMethod(self.view_window, "resetToInitialState", Qt.QueuedConnection)
        self.showMainMenu.emit()

    @pyqtSlot()
    def retryGame(self):
        print("ğŸ® ê²Œì„ì„ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤.")
        if self.last_video_path:
            self.startGame(self.last_video_path)
        else:
            print("â— ë§ˆì§€ë§‰ìœ¼ë¡œ í”Œë ˆì´í•œ ê²Œì„ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    @pyqtSlot()
    def showReplay(self):
        print("ğŸ¬ ë¦¬í”Œë ˆì´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
        self.view_window.setProperty('multiplayerScores', {})

        video_path = "resource/output.mp4"
        if os.path.exists(video_path):
            QMetaObject.invokeMethod(self.view_window, "playVideo", Qt.QueuedConnection, Q_ARG(QVariant, video_path))
        else:
            print(f"â— ë¦¬í”Œë ˆì´ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

    @pyqtSlot(str)
    def startGame(self, videoPath):
        if self.is_multi_player:
            self._startMultiPlayer(videoPath)
        else:
            self._startSinglePlayer(videoPath)

    def _startSinglePlayer(self, videoPath):
        if not videoPath:
            print("â— ë¹„ë””ì˜¤ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        if self.game_window and self.game_window.isVisible():
            print("â— ì´ë¯¸ ê²Œì„ì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return

        print(f"ğŸš€ ì‹±ê¸€ í”Œë ˆì´ì–´ ëª¨ë“œ ì‹œì‘: {videoPath}")
        self.last_video_path = videoPath  # ë§ˆì§€ë§‰ ë¹„ë””ì˜¤ ê²½ë¡œ ì €ì¥
        self.gameStarted.emit() # ê²Œì„ ì‹œì‘ ì‹ í˜¸ ì „ì†¡

        # ë°°ê²½ì„ ë¹„ë””ì˜¤ì—ì„œ ì´ë¯¸ì§€ë¡œ ë³€ê²½
        QMetaObject.invokeMethod(self.view_window, "showBackgroundImage", Qt.QueuedConnection)
        QMetaObject.invokeMethod(self.view_window, "stopForegroundVideo", Qt.QueuedConnection)

        # SinglePlayerAppì— í•„ìš”í•œ ì¸ì(args) ìƒì„±
        json_path = videoPath.replace(".mp4", ".json")
        args = Namespace(
            ref=videoPath,
            json=json_path,
            imgsz=640,
            device=self.device,
            conf_thres=0.5,
        )

        # SinglePlayerApp ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.game_window = SinglePlayerApp(args, self.model, self.use_half, self.ser)
        move_mid = 'w'
        self.ser.write(move_mid.encode())
        self.game_window.setAttribute(Qt.WA_DeleteOnClose) # ì°½ì´ ë‹«í ë•Œ ê°ì²´ ìë™ ì‚­ì œ
        
        # ê²Œì„ ì°½ì´ ë‹«í ë•Œ ì‹ í˜¸ë¥¼ ë°›ê¸° ìœ„í•´ ì—°ê²°
        self.game_window.destroyed.connect(self.onGameFinished)

        # ë©”ì¸ ë·°ì™€ ë™ì¼í•œ í™”ë©´ì— ì „ì²´ í™”ë©´ìœ¼ë¡œ í‘œì‹œ
        screen_for_view = self.screens[0]
        screen_geometry = screen_for_view.geometry()
        self.game_window.move(screen_geometry.topLeft())
        self.game_window.showFullScreen()

    def _startMultiPlayer(self, videoPath):
        if not videoPath:
            print("â— ë¹„ë””ì˜¤ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        if self.game_window and self.game_window.isVisible():
            print("â— ì´ë¯¸ ê²Œì„ì´ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return

        print(f"ğŸš€ ë©€í‹° í”Œë ˆì´ì–´ ëª¨ë“œ ì‹œì‘: {videoPath}")
        self.last_video_path = videoPath
        self.gameStarted.emit()

        QMetaObject.invokeMethod(self.view_window, "showBackgroundImage", Qt.QueuedConnection)
        QMetaObject.invokeMethod(self.view_window, "stopForegroundVideo", Qt.QueuedConnection)

        json_path = videoPath.replace(".mp4", ".json")
        args = Namespace(
            ref=videoPath,
            json=json_path,
            imgsz=640,
            device=self.device,
            conf_thres=0.5,
        )

        self.game_window = MultiPlayerApp(args, self.model, self.use_half, self.ser)
        move_mid = 'w'
        self.ser.write(move_mid.encode())
        self.game_window.setAttribute(Qt.WA_DeleteOnClose)
        
        self.game_window.destroyed.connect(self.onGameFinished)

        screen_for_view = self.screens[0]
        screen_geometry = screen_for_view.geometry()
        self.game_window.move(screen_geometry.topLeft())
        self.game_window.showFullScreen()

    def _merge_audio_to_output(self, reference_video_path):
        print(f"ğŸ”Š ì˜¤ë””ì˜¤ ë³‘í•© ì‹œì‘: 'resource/output.mp4'ì™€ '{reference_video_path}'ì˜ ì˜¤ë””ì˜¤ë¥¼ í•©ì¹©ë‹ˆë‹¤.")
        recorded_video = "resource/output.mp4"
        output_video_with_audio = "resource/output_with_audio.mp4"

        if not os.path.exists(recorded_video):
            print(f"â— ë…¹í™”ëœ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {recorded_video}")
            return

        command = [
            'ffmpeg',
            '-y',  # Overwrite output file if it exists
            '-i', recorded_video,
            '-i', reference_video_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-map', '0:v:0',
            '-map', '1:a:0',
            '-shortest',
            output_video_with_audio
        ]

        try:
            # ffmpeg ì‹¤í–‰, ë¡œê·¸ ì¶œë ¥ì„ ìœ„í•´ capture_output=True ì‚¬ìš©
            result = subprocess.run(command, check=True, capture_output=True, text=True)
            print(f"âœ… ì˜¤ë””ì˜¤ ë³‘í•© ì™„ë£Œ: {output_video_with_audio}")
            print(f"FFmpeg stdout: {result.stdout}")
            print(f"FFmpeg stderr: {result.stderr}")
        except subprocess.CalledProcessError as e:
            print(f"â— FFmpeg ì˜¤ë¥˜ ë°œìƒ:")
            print(f"Stderr: {e.stderr}")
        except FileNotFoundError:
            print("â— 'ffmpeg'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

    @pyqtSlot()
    def onGameFinished(self):
        print("ğŸ ê²Œì„ ì°½ì´ ë‹«í˜”ìŠµë‹ˆë‹¤.")
        move_mid = 'w'
        self.ser.write(move_mid.encode())

        # ì˜¤ë””ì˜¤ ë³‘í•© ì‹¤í–‰
        if self.last_video_path:
            self._merge_audio_to_output(self.last_video_path)
        else:
            print("â— last_video_pathê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì˜¤ë””ì˜¤ë¥¼ ë³‘í•©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if self.game_window:
            if self.is_multi_player:
                scores = self.game_window.final_score
                print(f"Multiplayer scores from game window: {scores}")
                self.showMultiplayerResult.emit(json.dumps(scores))
            else:
                score = self.game_window.final_score
                print(f"Final score from game window: {score}")
                self.showRank.emit(int(score))
        
        if self.is_multi_player:
            self.showPostGameMenu.emit("PostGameMenu_Multi.qml")
        else:
            self.showPostGameMenu.emit("PostGameMenu.qml")
            
        self.game_window = None

def main():
    app = QApplication(sys.argv)
    atexit.register(delete_output_files)
    app.setQuitOnLastWindowClosed(False)

    
    print("ğŸ§  YOLOv8 ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    model = YOLO("merge_test/yolov8l-pose.pt")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    try:
        model.fuse()
    except:
        pass
    use_half = (device == "cuda")
    if use_half:
        try:
            model.model.half()
        except:
            use_half = False
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
    model_data = {"model": model, "device": device, "use_half": use_half}

    screens = QGuiApplication.screens()
    print(f"ì´ {len(screens)}ê°œì˜ ëª¨ë‹ˆí„°ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    for i, screen in enumerate(screens):
        print(f"ğŸ–¥ï¸ ëª¨ë‹ˆí„° {i}: name={screen.name()}, geometry={screen.geometry()}")

    # --- HDMI ìš°ì„  ê²€ìƒ‰: "HDMI", "DP", "HDMI-" ë“± ì´ë¦„ì— HDMI/DP í‘œê¸°ê°€ ìˆëŠ” ìŠ¤í¬ë¦°ì„ ì°¾ìŒ ---
    screen_for_view = None
    screen_for_control = None

    if len(screens) > 1:
        # ìš°ì„  HDMI ê³„ì—´ë¡œ ë³´ì´ëŠ” ìŠ¤í¬ë¦° ì°¾ê¸°
        for screen in screens:
            name = screen.name().upper()
            if "HDMI" in name or "DP" in name or "DISPLAY" in name:
                screen_for_view = screen
                print(f"âœ… View(ì „ì²´í™”ë©´) í™”ë©´ìœ¼ë¡œ ì„ íƒ: {screen.name()}")
                break

        # ë§Œì•½ HDMIë¥¼ ëª» ì°¾ìœ¼ë©´ ì²« ë²ˆì§¸ë¥¼ viewë¡œ ì§€ì •
        if not screen_for_view:
            screen_for_view = screens[0]
            print("âš ï¸ HDMI/DP í‘œê¸°ê°€ ìˆëŠ” ëª¨ë‹ˆí„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ìŠ¤í¬ë¦°ì„ viewë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        # controlì€ viewì™€ ë‹¤ë¥¸ í™”ë©´ì„ ì“°ë„ë¡ ì‹œë„
        for screen in screens:
            if screen != screen_for_view:
                screen_for_control = screen
                print(f"âœ… Control í™”ë©´ìœ¼ë¡œ ì„ íƒ: {screen.name()}")
                break

    # ë‹¨ì¼ ëª¨ë‹ˆí„° ë˜ëŠ” control ëª» ì°¾ì•˜ì„ ë•Œì˜ í´ë°±
    if not screen_for_control:
        if len(screens) > 1:
            # ë‘ ë²ˆì§¸ ìŠ¤í¬ë¦°ë¥¼ controlë¡œ ì‚¬ìš©
            screen_for_control = screens[1] if screens[0] == screen_for_view else screens[0]
        else:
            # screen_for_control = screen_for_view
            screen_for_control = screens[0]
            screen_for_view = screens[0]

    single_monitor_mode = (len(screens) < 2)

    # ... (ëª¨ë¸ ë¡œë“œ ë“± ì¤‘ê°„ ìƒëµ) ...

    view_engine = QQmlApplicationEngine()
    main_engine = QQmlApplicationEngine()

    # ë¸Œë¦¿ì§€ ë“± ì„¤ì • (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    signalBridge = SignalBridge(None) 
    controlBridge = ControlBridge(screens, signalBridge, model_data, None)

    event_filter = AppEventFilter(controlBridge)
    app.installEventFilter(event_filter)

    view_engine.rootContext().setContextProperty("targetScreen", screen_for_view)
    view_engine.rootContext().setContextProperty("controlBridge", controlBridge)
    view_engine.rootContext().setContextProperty("pyBridge", controlBridge)
    view_engine.load(QUrl("Main_view.qml"))

    if not view_engine.rootObjects():
        print("â— Main_view.qml ë¡œë“œ ì‹¤íŒ¨")
        sys.exit(-1)

    view_window = view_engine.rootObjects()[0]

    # ë¸Œë¦¿ì§€ì— ìœˆë„ìš° ì„¤ì •
    signalBridge.main_view_window = view_window
    controlBridge.view_window = view_window

    # View í™”ë©´ì„ í•´ë‹¹ ìŠ¤í¬ë¦°ì— ë§ì¶° ì „ì²´í™”ë©´ìœ¼ë¡œ ë„ì›€
    try:
        # í™”ë©´ ìœ„ì¹˜/í¬ê¸° ë§ì¶¤
        view_window.setGeometry(screen_for_view.geometry())
        # ìµœìƒë‹¨ ìˆ˜ì¤€ ìœˆë„ìš°(ì˜ˆ: QWindow/QQuickWindow/Windowì¼ ê²½ìš°) ì „ì²´í™”ë©´ í˜¸ì¶œ
        view_window.showFullScreen()
        print(f"âœ… Main_view.qmlì„ í™”ë©´ '{screen_for_view.name()}'ì—ì„œ ì „ì²´í™”ë©´ìœ¼ë¡œ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âš ï¸ view_window ì „ì²´í™”ë©´ ì„¤ì • ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        # ì•ˆì „í•˜ê²Œ ì°½ëª¨ë“œë¡œ ë„ìš°ê¸°
        view_window.setGeometry(screen_for_view.geometry())
        view_window.show()
        print("âœ… ëŒ€ì²´ë¡œ ì°½ ëª¨ë“œë¡œ view_windowë¥¼ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.")

    # controlìª½ QML ë¡œë“œ
    main_engine.rootContext().setContextProperty("targetScreen", screen_for_control)
    main_engine.rootContext().setContextProperty("controlBridge", controlBridge)
    main_engine.rootContext().setContextProperty("pyBridge", controlBridge)
    main_engine.load(QUrl("Main_control.qml"))

    if not main_engine.rootObjects():
        print("â— Main_control.qml ë¡œë“œ ì‹¤íŒ¨")
        sys.exit(-1)

    main_window = main_engine.rootObjects()[0]

    # ê¸°ì¡´ì˜ ë³€í™˜ ì‹ í˜¸ ì—°ê²°
    controlBridge.conversionStarted.connect(lambda: main_window.showConvertingScreen())
    controlBridge.conversionFinishedForControl.connect(lambda: main_window.showConvertedScreen())

    # control ìœˆë„ìš° ë³´ì´ê¸°: ë‹¨ì¼ ëª¨ë‹ˆí„°ë©´ ì°½ ëª¨ë“œ (ìš°ì¸¡ì— ë¶™ì—¬ì„œ),
    # ë©€í‹° ëª¨ë‹ˆë©´ control ìŠ¤í¬ë¦°ì—ì„œ ì „ì²´í™”ë©´ìœ¼ë¡œ í‘œì‹œ(ì£¼ë¡œ í„°ì¹˜íŒ¨ë„ ë“±)
    if single_monitor_mode:
        screen_geo = screen_for_control.geometry()
        width = 400
        height = screen_geo.height()
        main_window.setGeometry(screen_geo.width() - width, 0, width, height)
        main_window.show()
        print("âœ… Main_control.qmlì„ ì°½ ëª¨ë“œë¡œ ë„ì›€ (ë‹¨ì¼ ëª¨ë‹ˆí„° ì„¤ì •)")
    else:
        # control í™”ë©´ì„ ì „ì²´í™”ë©´ìœ¼ë¡œ ë„ìš°ê¸° (ì›í•˜ë©´ ì°½ ëª¨ë“œë¡œ ë°”ê¿”ë„ ë¨)
        main_window.setGeometry(screen_for_control.geometry())
        main_window.showFullScreen()
        print(f"âœ… Main_control.qml ëª¨ë‹ˆí„° '{screen_for_control.name()}'ì— ì „ì²´í™”ë©´ìœ¼ë¡œ ë„ì›€")
    
    controlBridge.showAvatarScreen.connect(lambda: QMetaObject.invokeMethod(main_window, "showAvatarScreen", Qt.QueuedConnection))
    controlBridge.showAvatarScreen.connect(lambda: QMetaObject.invokeMethod(view_window, "showAvatarScreen", Qt.QueuedConnection))
    controlBridge.showCredits.connect(lambda: QMetaObject.invokeMethod(view_window, "showCreditVideo", Qt.QueuedConnection))
    controlBridge.showCredits.connect(lambda: QMetaObject.invokeMethod(main_window, "showCreditRoll", Qt.QueuedConnection))
    
    sys.exit(app.exec_())

if __name__ == "__main__":
    main()