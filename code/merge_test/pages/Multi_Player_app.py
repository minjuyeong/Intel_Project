#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import json
import numpy as np
import time
import os
from PyQt5.QtWidgets import (
    QWidget, QLabel, QVBoxLayout, QSizePolicy,
    QSplitter, QMessageBox, QHBoxLayout
)
from PyQt5.QtMultimedia import QMediaPlayer
from PyQt5.QtCore import QTimer, Qt, QRect, QCoreApplication, pyqtSignal
from PyQt5.QtGui import QImage, QPixmap, QFont, QColor, QPainter
from PyQt5.QtWidgets import QPushButton
import random
import threading
import sys
import torch
from ultralytics import YOLO
import collections

# BasePoseApp í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from .base_pose_app import BasePoseApp
# í¬ì¦ˆ ê°ì§€ ë° ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from core.pose_utils import (
    normalize_keypoints, pose_to_anglevec, frame_score_strict, draw_pose
)

from core.person_utils import get_midpoint_between_people, classify_region

# YOLO ëª¨ë¸ ì„¤ì •
MODEL_PATH_DEFAULT = "yolov8m-pose.pt"
DETECT_CONF_THRES = 0.25
KPT_CONF_THRES = 0.20

# í‚¤í¬ì¸íŠ¸ ìŒ (ì™¼ìª½ <-> ì˜¤ë¥¸ìª½)
FLIP_MAP = [
    [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]
]

class MultiPlayerApp(BasePoseApp):
    """
    BasePoseAppì„ ìƒì†ë°›ì•„ ë©€í‹° í”Œë ˆì´ì–´ ëª¨ë“œ ë¡œì§ì„ êµ¬í˜„í•œ í´ë˜ìŠ¤.
    Firebaseë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë¡œì»¬ì—ì„œë§Œ ì‘ë™í•˜ë„ë¡ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    goMainRequested = pyqtSignal()
    goRankRequested = pyqtSignal()
    updateDisplaySignal = pyqtSignal()

    def __init__(self, args, model, use_half, ser, player_count=2):
        super().__init__(args)
        
        self.ser = ser
        
        self.game_over_flag = False
        self.model = model
        self.use_half = use_half
        self.button_container = None
        self.tracker_yaml = "botsort.yaml"
        self.active_players = {} # í”Œë ˆì´ì–´ ID (1 ë˜ëŠ” 2) -> ì •ë³´
        self.previous_kps = {} # ê° í”Œë ˆì´ì–´ì˜ ì´ì „ í‚¤í¬ì¸íŠ¸ ì €ì¥

        # ì˜ìƒ ë…¹í™” ê´€ë ¨ ë³€ìˆ˜
        self.video_writer = None
        resource_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'resource')
        if not os.path.exists(resource_dir):
            os.makedirs(resource_dir)
        self.output_path = os.path.join(resource_dir, 'output.mp4')

        if self.args.json is None:
            QMessageBox.critical(self, "ì˜¤ë¥˜", "ì˜¤ë¥˜: JSON íŒŒì¼ ê²½ë¡œê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.close()
            return
        
        try:
            with open(self.args.json, 'r') as f:
                self.reference_data = json.load(f)["frames"]
                print(f"{len(self.reference_data)}ê°œì˜ ì°¸ì¡° í”„ë ˆì„ì„ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except FileNotFoundError:
            QMessageBox.critical(self, "ì˜¤ë¥˜", f"ì˜¤ë¥˜: ì°¸ì¡° JSON íŒŒì¼ '{self.args.json}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            self.close()
            return
        
        # ì‹¤ì‹œê°„ í”¼ë“œë°± ê´€ë ¨ UI ìš”ì†Œ ì‚­ì œ
        self.player_info_label = QLabel(self)
        self.player_info_label.setAlignment(Qt.AlignTop | Qt.AlignRight)
        self.player_info_label.setStyleSheet("color: white; background-color: rgba(0,0,0,150); padding: 10px;")
        self.player_info_label.hide()

        self.count = 6
        self.score_history = collections.defaultdict(list)
        self.score_history_length = 3
        self.follow_delay_ms = 200
        self.start_time = None
        self.end_time = None
        
        self.local_scores = collections.defaultdict(lambda: 80)
        self.player_rank_map = {}

        self.count_timer.start(1000)
        self.score_timer.timeout.connect(self.calculate_score)
        
        self.init_webcam()
        if self.args.ref is not None:
            self.show_preview_frame(self.args.ref)
    
    @property
    def final_score(self):
        return dict(self.local_scores)

    def play_video(self):
        super().play_video()
        self.start_time = time.time()

    def _flip_keypoints(self, kps):
        """í‚¤í¬ì¸íŠ¸ ìŒì„ ì¢Œìš° ë°˜ì „ì‹œí‚µë‹ˆë‹¤."""
        kps = kps.copy()
        for i, j in FLIP_MAP:
            kps[i], kps[j] = kps[j].copy(), kps[i].copy()
        return kps

    def update_player_info_display(self):
        """ì‹¤ì œ í”Œë ˆì´ì–´ì˜ ì ìˆ˜ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤. ì‹œê°ì ìœ¼ë¡œëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."""
        info_text = ""
        # ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ê³  ìˆœìœ„ ë¶€ì—¬
        sorted_players = sorted(self.local_scores.items(), key=lambda item: item[1], reverse=True)
        
        # IDì™€ ìˆœìœ„ ë§¤í•‘ ì—…ë°ì´íŠ¸
        player_ranks = {}
        for i, (player_id, score) in enumerate(sorted_players):
            if i > 0 and score == sorted_players[i-1][1]:
                player_ranks[player_id] = player_ranks[sorted_players[i-1][0]]
            else:
                player_ranks[player_id] = i + 1
        self.player_rank_map = player_ranks

        for player_id, score in sorted_players:
            score_to_display = int(score)
            display_name = f"Player {player_id}"
            info_text += f"{display_name}: {score_to_display}pts\n"
        
        # ì‹œê°ì  í‘œì‹œë§Œ ì œê±°
        self.player_info_label.setText(info_text)
        self.player_info_label.hide() # í•­ìƒ ìˆ¨ê¹€

    def infer_and_track_once(self, model, frame, tracker_yaml, imgsz, device, half):
        """
        ë©€í‹° í”Œë ˆì´ì–´ ì¶”ì ì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
        ë°˜í™˜: dict {track_id: (kps_xy(17,2), kps_conf(17,), box_xyxy(4,))}
        """
        with torch.inference_mode():
            results = model.track(frame, imgsz=imgsz, device=device, half=half,
                                  conf=DETECT_CONF_THRES, verbose=False,
                                  persist=True, tracker=tracker_yaml, stream=False)
        if not results:
            return {}
        res = results[0]
        if (res.keypoints is None) or (len(res.keypoints)==0):
            return {}
        
        ids = getattr(res.boxes, "id", None)
        out = {}
        if ids is not None:
            ids = ids.detach().cpu().numpy().astype(int)
            boxes = res.boxes.xyxy.detach().cpu().numpy()
            for i in range(len(ids)):
                tid = int(ids[i])
                kps = res.keypoints.xy[i].detach().cpu().numpy()
                conf = res.keypoints.conf[i].detach().cpu().numpy()
                kps[conf < KPT_CONF_THRES] = np.nan
                box = boxes[i].astype(float)
                out[tid] = (kps, conf, box)
        else:
            boxes = res.boxes.xyxy.detach().cpu().numpy()
            for i in range(len(boxes)):
                tid = i
                kps = res.keypoints.xy[i].detach().cpu().numpy()
                conf = res.keypoints.conf[i].detach().cpu().numpy()
                kps[conf < KPT_CONF_THRES] = np.nan
                box = boxes[i].astype(float)
                out[tid] = (kps, conf, box)
                
        return out

    def update_frame(self, force_refresh=False):
        """ì›¹ìº  í”„ë ˆì„ì„ ì—…ë°ì´íŠ¸í•˜ê³  í¬ì¦ˆ ê°ì§€ ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤."""
        if self.game_over_flag:
            return

        if self.cap and self.cap.isOpened():
            ret, frame = self.cap.read()
            if not ret or frame is None:
                return
            
            flipped_frame = cv2.flip(frame, 1)

            # í”„ë ˆì„ ì €ì¥ (ë…¹í™”ìš©)
            if self.video_writer:
                self.video_writer.write(flipped_frame)

            # YOLO + ì¶”ì 
            tracked_players = self.infer_and_track_once(
                self.model, flipped_frame, self.tracker_yaml,
                self.args.imgsz, self.args.device, self.use_half
            )
            display_frame = flipped_frame.copy()

            # x ì¢Œí‘œ ê¸°ì¤€ ì •ë ¬
            all_detected = list(tracked_players.values())
            all_detected.sort(key=lambda p: p[2][0])  # box.x1 ê¸°ì¤€
            
            new_active_players = {}
            kps_list = []

            # ìµœëŒ€ 2ëª…ì˜ í”Œë ˆì´ì–´ë¥¼ active_playersì— ì €ì¥
            for i, (kps, _, box) in enumerate(all_detected[:2]):
                player_id = i + 1
                new_active_players[player_id] = {'tid': player_id, 'kps': kps, 'box': box}
                if kps is not None:
                    kps_list.append(kps)

            self.active_players = new_active_players

            # --- ë‘ ì‚¬ëŒ ì¤‘ì‹¬ì˜ ì¤‘ê°„ì  ê³„ì‚° í›„ ì˜ì—­ ë¶„ë¥˜ ---
            midpoint = get_midpoint_between_people(kps_list)
            if midpoint is not None:
                mx, my = midpoint
                region = classify_region(mx, display_frame.shape[1])
                self.ser.write(region.encode())

            # í¬ì¦ˆ ê·¸ë¦¬ê¸°
            self.draw_all_poses(display_frame)

            # Qt í™”ë©´ í‘œì‹œ
            frame_rgb = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            h, w, ch = frame_rgb.shape
            qt_image = QImage(frame_rgb.data, w, h, ch * w, QImage.Format_RGB888)
            pixmap = QPixmap.fromImage(qt_image)
            self.cam_label.setPixmap(
                pixmap.scaled(self.cam_label.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
            )



    def draw_all_poses(self, frame):
        """
        ì¶”ì ëœ ëª¨ë“  í”Œë ˆì´ì–´ì˜ í¬ì¦ˆì™€ IDë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
        """
        for player_id, player_data in self.active_players.items():
            kps = player_data['kps']
            box = player_data['box']
            if kps is not None and box is not None:
                display_name = f"Player {player_id}"
                
                # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
                x1, y1, x2, y2 = box
                cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
                
                # í¬ì¦ˆ ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.
                draw_pose(frame, kps)
                
                # í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 1
                thickness = 2
                text_size = cv2.getTextSize(display_name, font, font_scale, thickness)[0]
                text_x = int(x1)
                text_y = int(y1) - 10
                
                # í…ìŠ¤íŠ¸ ë°°ê²½ì„ ê·¸ë¦½ë‹ˆë‹¤.
                cv2.rectangle(frame, (text_x, text_y - text_size[1] - 5), (text_x + text_size[0] + 5, text_y + 5), (0, 0, 0), -1)
                cv2.putText(frame, display_name, (text_x + 2, text_y - 2), font, font_scale, (255, 255, 255), thickness, cv2.LINE_AA)


    def calculate_score(self):
        """ì›¹ìº  í”„ë ˆì„ê³¼ ì°¸ê³  í¬ì¦ˆë¥¼ ë¹„êµí•˜ì—¬ ëª¨ë“  í”Œë ˆì´ì–´ì˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not self.cap or not self.cap.isOpened() or self.count > 0 or self.game_over_flag:
            return

        ret, frame = self.cap.read()
        if not ret or frame is None:
            return

        # ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì¢Œìš° ë°˜ì „í•©ë‹ˆë‹¤. ì´ í”„ë ˆì„ìœ¼ë¡œ í¬ì¦ˆë¥¼ ê°ì§€í•˜ê³  ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        flipped_frame = cv2.flip(frame, 1)
      
        

        tracked_players = self.infer_and_track_once(self.model, flipped_frame, self.tracker_yaml, self.args.imgsz, self.args.device, self.use_half)
        
        # í”Œë ˆì´ì–´ë¥¼ xì¶• ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ Player 1ê³¼ Player 2ë¥¼ ê²°ì •í•˜ê³  ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        all_detected = list(tracked_players.values())
        all_detected.sort(key=lambda p: p[2][0]) # boxì˜ x1 ì¢Œí‘œ(p[2][0])ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬

        # ìµœëŒ€ 2ëª…ì˜ í”Œë ˆì´ì–´ì— ëŒ€í•´ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        for i, (cam_kps, cam_conf, _) in enumerate(all_detected[:2]):
            player_id = i + 1 # Player 1 ë˜ëŠ” Player 2

            if cam_kps is not None and cam_kps.size > 0 and len(self.reference_data) > 0:
                delayed_position = self.player.position() - self.follow_delay_ms
                if delayed_position < 0: delayed_position = 0
                ref_frame_index = int(delayed_position / 1000 * 30)
                ref_data_index = ref_frame_index // 10

                if ref_data_index < len(self.reference_data):
                    ref_data = self.reference_data[ref_data_index]
                    ref_kps = np.array(ref_data["kps"])

                    cam_kps_norm = normalize_keypoints(cam_kps)
                    ref_kps_norm = normalize_keypoints(ref_kps)

                    vec_ref = pose_to_anglevec(ref_kps_norm)
                    vec_live = pose_to_anglevec(cam_kps_norm)
                    
                    # --- ì ìˆ˜ ê°€ì¤‘ì¹˜ ì ìš© ë¡œì§ ì‹œì‘ ---
                    num_angles = len(vec_ref)
                    weights = np.ones(num_angles)
                    weights[0:4] = 2.0
                    vec_ref_weighted = vec_ref * weights
                    vec_live_weighted = vec_live * weights
                    current_score, _, _ = frame_score_strict(vec_ref_weighted, vec_live_weighted)
                    # --- ì ìˆ˜ ê°€ì¤‘ì¹˜ ì ìš© ë¡œì§ ë ---
                    
                    # --- ì •ì§€ í˜ë„í‹° ë¡œì§ ì¶”ê°€ ì‹œì‘ ---
                    if player_id in self.previous_kps and self.previous_kps[player_id] is not None:
                        kps_diff = np.linalg.norm(cam_kps - self.previous_kps[player_id])
                        movement_threshold = 20.0
                        if kps_diff < movement_threshold:
                            current_score -= 5
                            if current_score < 0:
                                current_score = 0
                    
                    self.previous_kps[player_id] = cam_kps.copy()
                    # --- ì •ì§€ í˜ë„í‹° ë¡œì§ ì¶”ê°€ ë ---
                    
                    if current_score != -1.0:
                        self.score_history[player_id].append(current_score)
                    
                    if len(self.score_history[player_id]) >= self.score_history_length:
                        smoothed_score = np.mean(self.score_history[player_id])
                        
                        current_total_score = self.local_scores[player_id]
                        if smoothed_score >= 70.0:
                            self.local_scores[player_id] = min(100, current_total_score + 1)
                        elif smoothed_score < 30.0:
                            self.local_scores[player_id] = max(0, current_total_score - 1)
                        
                        self.score_history[player_id] = []
        
        self.update_player_info_display()

    def update_countdown(self):
        """
        ì¹´ìš´íŠ¸ë‹¤ìš´ì„ ì—…ë°ì´íŠ¸í•˜ê³ , ì¹´ìš´íŠ¸ë‹¤ìš´ì´ ëë‚˜ë©´ ê²Œì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.
        """
        self.count -= 1
        overlay_font_size = int(self.cam_label.height() / 5)
        self.overlay_label.setFont(QFont("Arial", overlay_font_size, QFont.Bold))
        self.overlay_label.setGeometry(self.cam_label.rect())
        
        if self.count > 0:
            self.overlay_label.setText(str(self.count))
        elif self.count == 0:
            self.overlay_label.setText("START")
            # ë…¹í™” ì‹œì‘
            if self.cap and self.cap.isOpened():
                width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = self.cap.get(cv2.CAP_PROP_FPS)
                if fps == 0:
                    fps = 30 # ê¸°ë³¸ FPS
                self.video_writer = cv2.VideoWriter(self.output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))
                print(f"ğŸ¥ ì›¹ìº  ë…¹í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ì €ì¥ ê²½ë¡œ: {self.output_path}")
        else:
            self.overlay_label.hide()
            self.count_timer.stop()
            self.video_stack.setCurrentWidget(self.video_widget)
            QTimer.singleShot(0, self.equalize_splitter)
            self.play_video()
            self.score_timer.start(333)

    def handle_video_state(self, state):
        """ë¶€ëª¨ í´ë˜ìŠ¤ì˜ ë¹„ë””ì˜¤ ìƒíƒœ ê°ì§€ ë©”ì„œë“œë¥¼ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ ê²Œì„ ì¢…ë£Œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        if state == QMediaPlayer.StoppedState:
            print("ë¹„ë””ì˜¤ ì¬ìƒì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì°½ì„ ë‹«ìŠµë‹ˆë‹¤.")
            self.game_over_flag = True
            self.end_time = time.time() # ê²Œì„ ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
            
            # ë…¹í™” ì¢…ë£Œ
            if self.video_writer:
                self.video_writer.release()
                self.video_writer = None
                print(f"âœ… ì˜ìƒì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {self.output_path}")

            self.close() # Close the window

    def closeEvent(self, event):
        """ì°½ì´ ë‹«í ë•Œ í˜¸ì¶œë˜ëŠ” ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬."""
        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None
            print("â„¹ï¸ ì°½ì´ ë‹«í˜€ ë…¹í™”ë¥¼ ì¤‘ì§€í•˜ê³  ì˜ìƒì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        super().closeEvent(event)

    def resizeEvent(self, event):
        super().resizeEvent(event)
        if self.count > 0:
            self.overlay_label.setGeometry(self.cam_label.rect())
            overlay_font_size = int(self.cam_label.height() / 5)
            self.overlay_label.setFont(QFont("Arial", overlay_font_size, QFont.Bold))
